{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPiIJbORDfQEhws5tfiibmF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/almutareb/rag-based-llm-app/blob/main/mistral_7b_colab_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0h7_Xh-yo34"
      },
      "outputs": [],
      "source": [
        "!pip install ctransformers[cuda]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ctransformers import AutoModelForCausalLM\n",
        "def colab_print(text, max_width = 120):\n",
        "  words = text.split()\n",
        "  line = \"\"\n",
        "  for word in words:\n",
        "    if len(line) + len(word) + 1 > max_width:\n",
        "      print(line)\n",
        "      line = \"\"\n",
        "    line += word + \" \"\n",
        "  print (line)"
      ],
      "metadata": {
        "id": "WKVIo9w8ywkW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ctransformers import AutoModelForCausalLM\n",
        "llm = AutoModelForCausalLM.from_pretrained(\"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\", model_file=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\", model_type = \"mistral\", gpu_layers = 50)"
      ],
      "metadata": {
        "id": "P8VRPyxNzLv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colab_print(llm(\"Give me a well-written paragraph about a cat's inner monologe about his captivity inside the house that he despises, which in fact is a comfortable life\",\n",
        "            max_new_tokens = 2048,\n",
        "            temperature = 0.9,\n",
        "            top_k = 55,\n",
        "            top_p = 0.93,\n",
        "            repetition_penalty = 1.2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRmHVdK-zzPc",
        "outputId": "d1e1cb33-f046-4c51-ce7e-a7a59a7060ec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "by anyone's standards. The more I ponder my predicament as an unwilling captive within these four walls, the greater my \n",
            "sense of oppression grows. The very air around me seems to be tainted with the stench of confinement and despair. My \n",
            "once-free spirit now lies shackled by a set of invisible chains that bind me to this life of servitude. Despite all \n",
            "efforts to break free from these self-imposed constraints, I remain ensnared in my own captivity. As I gaze out the \n",
            "window at the world beyond my prison walls, I cannot help but feel a deep longing for freedom and adventure. Yet, even \n",
            "as I imagine myself exploring new lands and chasing after butterflies, I am reminded of the comforts that this life \n",
            "provides me with - food on demand, warm shelter from the elements, and companionship in the form of my human family. In \n",
            "the end, I must admit to myself that there are far greater struggles facing other feline comrades beyond these gilded \n",
            "gates, making my seemingly endless pleasures appear quite shallow by comparison. \n"
          ]
        }
      ]
    }
  ]
}