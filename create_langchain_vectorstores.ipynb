{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNlTIA8qMVtGfPiaewQigpN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/almutareb/rag-based-llm-app/blob/main/create_langchain_vectorstores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_Afchz-G20g"
      },
      "outputs": [],
      "source": [
        "# install needed packages\n",
        "!pip install -qU transformers accelerate einops langchain xformers bitsandbytes faiss-gpu sentence_transformers typing-extensions==4.8.0 unstructured chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilwnj-QNONu7",
        "outputId": "92902c0a-57c1-4d2d-dbb4-a3d58d8b061a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
        "\n",
        "from bs4 import BeautifulSoup as Soup\n",
        "\n",
        "urls = [\"https://langchain-doc.readthedocs.io/en/latest\",\"https://python.langchain.com/docs/get-started\"]\n",
        "docs = []\n",
        "for url in urls:\n",
        "  loader = RecursiveUrlLoader(url=url, max_depth=10, extractor=lambda x: Soup(x, \"html.parser\").text)\n",
        "  docs.extend(loader.load())\n",
        "#documents = loader.load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-JJ7wFjOT2b",
        "outputId": "514ade26-63db-48a9-dd98-957977f9d0d9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-66a2e94a9cf8>:8: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  loader = RecursiveUrlLoader(url=url, max_depth=10, extractor=lambda x: Soup(x, \"html.parser\").text)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW2qy2BbRQHv",
        "outputId": "73949bfc-9fbe-4d14-b480-006ad8d1b5f7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "287"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import ReadTheDocsLoader\n",
        "from langchain.text_splitter import HTMLHeaderTextSplitter\n",
        "from langchain.text_splitter import MarkdownTextSplitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores.utils import filter_complex_metadata\n",
        "import time\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "FAISS_INDEX_PATH = \"/content/lc-faiss-multi-mpnet-1000-markdown\"\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"],\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap  = 50,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "markdown_splitter = MarkdownTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "\n",
        "# Stage one: read all the docs, split them into chunks.\n",
        "st = time.time()\n",
        "print('Loading documents ...')\n",
        "#loader = ReadTheDocsLoader(documents_path)\n",
        "#docs = loader.load()\n",
        "chunks = text_splitter.create_documents([doc.page_content for doc in documents], metadatas=[doc.metadata for doc in documents])\n",
        "et = time.time() - st\n",
        "print(f'Time taken: {et} seconds.')\n",
        "\n",
        "#Stage two: embed the docs.\n",
        "# use all-mpnet-base-v2 sentence transformer to convert pieces of text in vectors to store them in the vector store\n",
        "model_name = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
        "model_kwargs = {\"device\": \"cuda\"}\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs\n",
        "    )\n",
        "#print(f'Loading chunks into faiss vector store ...')\n",
        "#st = time.time()\n",
        "#db_faiss = FAISS.from_documents(chunks, embeddings)\n",
        "#db_faiss.save_local(FAISS_INDEX_PATH)\n",
        "#et = time.time() - st\n",
        "#print(f'Time taken: {et} seconds.')\n",
        "print(f'Loading chunks into chroma vector store ...')\n",
        "st = time.time()\n",
        "persist_directory='/content/lc-chroma-multi-mpnet-500'\n",
        "db_chroma = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
        "et = time.time() - st\n",
        "print(f'Time taken: {et} seconds.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxZlgM25PgpC",
        "outputId": "1be05719-47e9-4751-b4b7-f92ababbe174"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading documents ...\n",
            "Time taken: 0.8861393928527832 seconds.\n",
            "Loading chunks into chroma vector store ...\n",
            "Time taken: 0.23302841186523438 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D3QkuBrU9G_",
        "outputId": "ba560cf4-6136-44c1-b3af-aee0c04cf7ca"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9587"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/lc-chroma* /content/drive/MyDrive/RAG_DB"
      ],
      "metadata": {
        "id": "sbkVRa4zP08w"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}